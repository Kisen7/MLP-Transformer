{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from py_file.MLP import MiddleLayer, OutputLayer\n",
    "from py_file.pkl_data_ori import load_data\n",
    "from py_file.transformer import PositionalEmbedding, Transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ori, x_test_ori, x_valid_ori, y_train, y_test, y_valid = load_data()\n",
    "print(x_train_ori.shape, x_test_ori.shape, x_valid_ori.shape)\n",
    "print(y_train.shape, y_test.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练后各模型MAE\n",
    "ori_mae = [0.194, 0.1994, 0.1963, 0.1972]\n",
    "# for i in range(4):\n",
    "#     model = tf.keras.models.load_model('./models/transformer_smooth_gelu_stack1_'+str(i)+'in4_best_model.h5',custom_objects={\"PositionalEmbedding\": PositionalEmbedding, \"Transformer_encoder\":Transformer_encoder})\n",
    "#     mse_mae = model.evaluate(x_test_ori, y_test, batch_size=256)\n",
    "#     ori_mae.append(mse_mae[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mid = 32\n",
    "n_out = 4\n",
    "eta = 0.000001\n",
    "epochs = 5\n",
    "batch_size = 100000\n",
    "pred, true = [], []\n",
    "\n",
    "window_size = x_train_ori.shape[1]\n",
    "figures_size = x_train_ori.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(figures_size):\n",
    "    x_train.append(x_train_ori[:, :, i])\n",
    "\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化MLP\n",
    "InputLayers = [MiddleLayer(window_size, n_mid)] * figures_size\n",
    "\n",
    "DenseLayers = [MiddleLayer(n_mid * figures_size, n_mid),\n",
    "            OutputLayer(n_mid, n_out)]\n",
    "\n",
    "# 正向传播\n",
    "def forward_propagation(x_figures):\n",
    "    x_lst = []\n",
    "    for i, layer in enumerate(InputLayers):\n",
    "        layer.forward(x_figures[i])\n",
    "        x_lst.append(layer.y)\n",
    "    \n",
    "    x = np.concatenate(x_lst, axis=1)\n",
    "    for layer in DenseLayers:\n",
    "        layer.forward(x)\n",
    "        x = layer.y      \n",
    "    return x\n",
    "    \n",
    "# 反向传播\n",
    "def backpropagation(t):\n",
    "    grad_y = t\n",
    "    grad_y_lst = []\n",
    "\n",
    "    for layer in reversed(DenseLayers):\n",
    "        layer.backward(grad_y)\n",
    "        grad_y = layer.grad_x\n",
    "        \n",
    "    grad_y_split = np.split(grad_y, figures_size, axis=1)\n",
    "    for i, layer in enumerate(InputLayers):\n",
    "        layer.backward(grad_y_split[i])\n",
    "        grad_y_lst.append(layer.grad_x)\n",
    "    return grad_y_lst\n",
    "\n",
    "# 参数更新\n",
    "def update_params():\n",
    "    for layer in InputLayers:\n",
    "        layer.update(eta)\n",
    "    for layer in DenseLayers:\n",
    "        layer.update(eta)\n",
    "\n",
    "# 误差测定\n",
    "def get_error(x, t):\n",
    "    y = forward_propagation(x)\n",
    "    # 交差熵误差\n",
    "    return -np.sum(t*np.log(y+1e-7)) / len(y)\n",
    "\n",
    "def get_n(mat):\n",
    "    temp = []\n",
    "    for i in mat:\n",
    "        temp.append(np.argmax(i))\n",
    "    return max(temp,key=temp.count)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(kd=70, nh=70):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(10, 15)),\n",
    "        PositionalEmbedding(d_model=15),\n",
    "        Transformer_encoder(key_dim=kd, num_heads=nh),\n",
    "        keras.layers.Dense(86, activation=\"gelu\", kernel_regularizer=keras.regularizers.l1_l2(0.1, 0.1)),\n",
    "        keras.layers.SpatialDropout1D(0.2),\n",
    "        keras.layers.GlobalAveragePooling1D(data_format='channels_last'),\n",
    "        keras.layers.Dense(1, activation='linear'),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_temp_path(n):\n",
    "    return './temp/transformer_smooth_gelu_stack1_'+str(n)+'in4_best_model.h5'\n",
    "\n",
    "def get_save_path(n):\n",
    "    return './models/transformer_smooth_gelu_stack1_'+str(n)+'in4_best_model.h5'\n",
    "\n",
    "def get_t(x_train_batch, y_train_batch):    \n",
    "    flag=True\n",
    "    diff_arr = []\n",
    "    # x_train_b, x_valid_b, y_train_b, y_valid_b = train_test_split(x_train_batch, y_train_batch, test_size=0.1)\n",
    "    for i in range(n_out):\n",
    "        temp_model = tf.keras.models.load_model(get_save_path(i),custom_objects={\"PositionalEmbedding\": PositionalEmbedding, \"Transformer_encoder\":Transformer_encoder})\n",
    "        temp_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse',metrics=['mae'])\n",
    "        print(f\"Traing model_{i+1}: \")\n",
    "\n",
    "        history = temp_model.fit(x_train_batch, y_train_batch,\n",
    "                            validation_data=(x_test_ori, y_test),  \n",
    "                            # callbacks=[save_best],\n",
    "                            batch_size=32, epochs=5, verbose=1)       \n",
    "        diff = history.history['val_mae'][-1] - history.history['val_mae'][0]\n",
    "        \n",
    "        print(f\"val: {diff}\")\n",
    "        diff_arr.append(diff)\n",
    "        \n",
    "        temp_model.save(get_temp_path(i))\n",
    "\n",
    "    t = np.zeros(n_out) \n",
    "    min_diff = min(diff_arr)\n",
    "\n",
    "\n",
    "    if min_diff < 0:\n",
    "        min_index = diff_arr.index(min_diff)\n",
    "        \n",
    "        t[min_index] = 1\n",
    "        temp_list = [t.copy() for _ in range(x_train_batch.shape[0])]\n",
    "        t = np.vstack(temp_list)\n",
    "\n",
    "        # if epoch_now >= 3:\n",
    "        shutil.move(get_temp_path(min_index), get_save_path(min_index))\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "    else:\n",
    "        flag = False\n",
    "    return t, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch_1-----\n",
      "-----batch 1-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 95s 29ms/step - loss: 0.0741 - mae: 0.2024 - val_loss: 0.0698 - val_mae: 0.1936\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0739 - mae: 0.2021 - val_loss: 0.0713 - val_mae: 0.1959\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0736 - mae: 0.2015 - val_loss: 0.0709 - val_mae: 0.1953\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0732 - mae: 0.2014 - val_loss: 0.0741 - val_mae: 0.1987\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0729 - mae: 0.2009 - val_loss: 0.0710 - val_mae: 0.1943\n",
      "val: 0.0006446540355682373\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 93s 29ms/step - loss: 0.0710 - mae: 0.1991 - val_loss: 0.0695 - val_mae: 0.1957\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0703 - mae: 0.1984 - val_loss: 0.0722 - val_mae: 0.2005\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 93s 30ms/step - loss: 0.0702 - mae: 0.1985 - val_loss: 0.0695 - val_mae: 0.1957\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0700 - mae: 0.1981 - val_loss: 0.0693 - val_mae: 0.1977\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0700 - mae: 0.1980 - val_loss: 0.0737 - val_mae: 0.2053\n",
      "val: 0.009596288204193115\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 93s 29ms/step - loss: 0.0744 - mae: 0.2034 - val_loss: 0.0698 - val_mae: 0.1914\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0743 - mae: 0.2032 - val_loss: 0.0731 - val_mae: 0.1994\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0737 - mae: 0.2026 - val_loss: 0.0753 - val_mae: 0.1993\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0735 - mae: 0.2022 - val_loss: 0.0706 - val_mae: 0.1930\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0730 - mae: 0.2015 - val_loss: 0.0707 - val_mae: 0.1925\n",
      "val: 0.001091986894607544\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 93s 29ms/step - loss: 0.0696 - mae: 0.1973 - val_loss: 0.0697 - val_mae: 0.1933\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0691 - mae: 0.1969 - val_loss: 0.0686 - val_mae: 0.1944\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0692 - mae: 0.1969 - val_loss: 0.0719 - val_mae: 0.2045\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0689 - mae: 0.1967 - val_loss: 0.0724 - val_mae: 0.2041\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0688 - mae: 0.1966 - val_loss: 0.0695 - val_mae: 0.1960\n",
      "val: 0.002717643976211548\n",
      "-----batch 2-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 93s 29ms/step - loss: 0.0741 - mae: 0.2022 - val_loss: 0.0696 - val_mae: 0.1943\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0732 - mae: 0.2017 - val_loss: 0.0716 - val_mae: 0.2008\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 92s 29ms/step - loss: 0.0729 - mae: 0.2014 - val_loss: 0.0710 - val_mae: 0.1983\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0730 - mae: 0.2012 - val_loss: 0.0697 - val_mae: 0.1908\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 91s 29ms/step - loss: 0.0725 - mae: 0.2006 - val_loss: 0.0703 - val_mae: 0.1970\n",
      "val: 0.0026337355375289917\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 93s 29ms/step - loss: 0.0701 - mae: 0.1983 - val_loss: 0.0718 - val_mae: 0.2026\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0700 - mae: 0.1981 - val_loss: 0.0693 - val_mae: 0.1942\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0698 - mae: 0.1978 - val_loss: 0.0689 - val_mae: 0.1912\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 93s 30ms/step - loss: 0.0697 - mae: 0.1977 - val_loss: 0.0674 - val_mae: 0.1907\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0693 - mae: 0.1973 - val_loss: 0.0705 - val_mae: 0.1948\n",
      "val: -0.007837727665901184\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0744 - mae: 0.2036 - val_loss: 0.0718 - val_mae: 0.1985\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0740 - mae: 0.2031 - val_loss: 0.0713 - val_mae: 0.1946\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0734 - mae: 0.2025 - val_loss: 0.0731 - val_mae: 0.1967\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0731 - mae: 0.2023 - val_loss: 0.0707 - val_mae: 0.1990\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0725 - mae: 0.2016 - val_loss: 0.0720 - val_mae: 0.1925\n",
      "val: -0.0060104429721832275\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0697 - mae: 0.1979 - val_loss: 0.0683 - val_mae: 0.1927\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0693 - mae: 0.1971 - val_loss: 0.0682 - val_mae: 0.1898\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0693 - mae: 0.1972 - val_loss: 0.0706 - val_mae: 0.2046\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0689 - mae: 0.1969 - val_loss: 0.0717 - val_mae: 0.1985\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1967 - val_loss: 0.0694 - val_mae: 0.1919\n",
      "val: -0.0008137822151184082\n",
      "-----Epoch_2-----\n",
      "-----batch 1-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0742 - mae: 0.2024 - val_loss: 0.0708 - val_mae: 0.1976\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2018 - val_loss: 0.0724 - val_mae: 0.1964\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0736 - mae: 0.2017 - val_loss: 0.0705 - val_mae: 0.1953\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0731 - mae: 0.2010 - val_loss: 0.0768 - val_mae: 0.2058\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0727 - mae: 0.2005 - val_loss: 0.0757 - val_mae: 0.1988\n",
      "val: 0.001156449317932129\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0702 - mae: 0.1981 - val_loss: 0.0703 - val_mae: 0.1937\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0695 - mae: 0.1975 - val_loss: 0.0756 - val_mae: 0.1998\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0699 - mae: 0.1977 - val_loss: 0.0695 - val_mae: 0.1972\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0697 - mae: 0.1976 - val_loss: 0.0704 - val_mae: 0.2013\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0693 - mae: 0.1971 - val_loss: 0.0704 - val_mae: 0.1985\n",
      "val: 0.0047996193170547485\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0745 - mae: 0.2035 - val_loss: 0.0727 - val_mae: 0.1993\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0740 - mae: 0.2030 - val_loss: 0.0701 - val_mae: 0.1919\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0737 - mae: 0.2026 - val_loss: 0.0699 - val_mae: 0.1965\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0733 - mae: 0.2019 - val_loss: 0.0723 - val_mae: 0.1985\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0730 - mae: 0.2016 - val_loss: 0.0763 - val_mae: 0.2023\n",
      "val: 0.002930864691734314\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0696 - mae: 0.1974 - val_loss: 0.0686 - val_mae: 0.1932\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0694 - mae: 0.1970 - val_loss: 0.0706 - val_mae: 0.1964\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0693 - mae: 0.1973 - val_loss: 0.0697 - val_mae: 0.1935\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0689 - mae: 0.1966 - val_loss: 0.0721 - val_mae: 0.2038\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0688 - mae: 0.1966 - val_loss: 0.0678 - val_mae: 0.1943\n",
      "val: 0.001161232590675354\n",
      "-----batch 2-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0740 - mae: 0.2025 - val_loss: 0.0699 - val_mae: 0.1951\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2021 - val_loss: 0.0737 - val_mae: 0.2025\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0733 - mae: 0.2018 - val_loss: 0.0726 - val_mae: 0.1970\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0729 - mae: 0.2012 - val_loss: 0.0705 - val_mae: 0.1931\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0726 - mae: 0.2006 - val_loss: 0.0697 - val_mae: 0.1922\n",
      "val: -0.002878040075302124\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0695 - mae: 0.1975 - val_loss: 0.0699 - val_mae: 0.1979\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0692 - mae: 0.1972 - val_loss: 0.0681 - val_mae: 0.1967\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1968 - val_loss: 0.0719 - val_mae: 0.1979\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0688 - mae: 0.1967 - val_loss: 0.0693 - val_mae: 0.1977\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0687 - mae: 0.1967 - val_loss: 0.0689 - val_mae: 0.1920\n",
      "val: -0.005894884467124939\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0745 - mae: 0.2038 - val_loss: 0.0723 - val_mae: 0.2004\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0738 - mae: 0.2031 - val_loss: 0.0709 - val_mae: 0.1939\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2027 - val_loss: 0.0708 - val_mae: 0.1938\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0732 - mae: 0.2021 - val_loss: 0.0719 - val_mae: 0.1981\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0726 - mae: 0.2014 - val_loss: 0.0720 - val_mae: 0.1985\n",
      "val: -0.001881226897239685\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0696 - mae: 0.1976 - val_loss: 0.0731 - val_mae: 0.1981\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0692 - mae: 0.1971 - val_loss: 0.0676 - val_mae: 0.1950\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0692 - mae: 0.1972 - val_loss: 0.0707 - val_mae: 0.1914\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1969 - val_loss: 0.0698 - val_mae: 0.1971\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0688 - mae: 0.1965 - val_loss: 0.0710 - val_mae: 0.2036\n",
      "val: 0.005476713180541992\n",
      "-----Epoch_3-----\n",
      "-----batch 1-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0741 - mae: 0.2024 - val_loss: 0.0726 - val_mae: 0.1981\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0737 - mae: 0.2019 - val_loss: 0.0697 - val_mae: 0.1926\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0736 - mae: 0.2016 - val_loss: 0.0700 - val_mae: 0.1930\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0731 - mae: 0.2011 - val_loss: 0.0742 - val_mae: 0.1923\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0729 - mae: 0.2009 - val_loss: 0.0718 - val_mae: 0.1982\n",
      "val: 8.106231689453125e-05\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0694 - mae: 0.1974 - val_loss: 0.0721 - val_mae: 0.2056\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0696 - mae: 0.1976 - val_loss: 0.0688 - val_mae: 0.1959\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0691 - mae: 0.1971 - val_loss: 0.0685 - val_mae: 0.1986\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0691 - mae: 0.1967 - val_loss: 0.0708 - val_mae: 0.1921\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1972 - val_loss: 0.0713 - val_mae: 0.2059\n",
      "val: 0.00036622583866119385\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0744 - mae: 0.2033 - val_loss: 0.0727 - val_mae: 0.1995\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0740 - mae: 0.2028 - val_loss: 0.0717 - val_mae: 0.1973\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0735 - mae: 0.2026 - val_loss: 0.0712 - val_mae: 0.1952\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0732 - mae: 0.2021 - val_loss: 0.0744 - val_mae: 0.2001\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0730 - mae: 0.2017 - val_loss: 0.0749 - val_mae: 0.2021\n",
      "val: 0.002593010663986206\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0694 - mae: 0.1971 - val_loss: 0.0728 - val_mae: 0.1996\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0695 - mae: 0.1972 - val_loss: 0.0693 - val_mae: 0.1958\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0692 - mae: 0.1970 - val_loss: 0.0704 - val_mae: 0.2026\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0691 - mae: 0.1968 - val_loss: 0.0678 - val_mae: 0.1971\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0686 - mae: 0.1963 - val_loss: 0.0674 - val_mae: 0.1956\n",
      "val: -0.003973037004470825\n",
      "-----batch 2-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0737 - mae: 0.2022 - val_loss: 0.0719 - val_mae: 0.1948\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0735 - mae: 0.2019 - val_loss: 0.0708 - val_mae: 0.1932\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0731 - mae: 0.2014 - val_loss: 0.0702 - val_mae: 0.1948\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0729 - mae: 0.2010 - val_loss: 0.0729 - val_mae: 0.2022\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0726 - mae: 0.2008 - val_loss: 0.0719 - val_mae: 0.1969\n",
      "val: 0.0020846575498580933\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0687 - mae: 0.1964 - val_loss: 0.0681 - val_mae: 0.1934\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0686 - mae: 0.1964 - val_loss: 0.0697 - val_mae: 0.1974\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1962 - val_loss: 0.0689 - val_mae: 0.1937\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1962 - val_loss: 0.0776 - val_mae: 0.2093\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0682 - mae: 0.1960 - val_loss: 0.0696 - val_mae: 0.1933\n",
      "val: -0.00012356042861938477\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0741 - mae: 0.2033 - val_loss: 0.0729 - val_mae: 0.1959\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0738 - mae: 0.2031 - val_loss: 0.0698 - val_mae: 0.1910\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2025 - val_loss: 0.0728 - val_mae: 0.2026\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0731 - mae: 0.2022 - val_loss: 0.0732 - val_mae: 0.2017\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0729 - mae: 0.2016 - val_loss: 0.0762 - val_mae: 0.2090\n",
      "val: 0.01313917338848114\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.0690 - mae: 0.1971 - val_loss: 0.0691 - val_mae: 0.1936\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1968 - val_loss: 0.0698 - val_mae: 0.1961\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0689 - mae: 0.1966 - val_loss: 0.0685 - val_mae: 0.1967\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0684 - mae: 0.1963 - val_loss: 0.0716 - val_mae: 0.2016\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1961 - val_loss: 0.0728 - val_mae: 0.2005\n",
      "val: 0.006958276033401489\n",
      "-----Epoch_4-----\n",
      "-----batch 1-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0741 - mae: 0.2025 - val_loss: 0.0718 - val_mae: 0.1986\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0738 - mae: 0.2019 - val_loss: 0.0707 - val_mae: 0.1952\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0737 - mae: 0.2018 - val_loss: 0.0737 - val_mae: 0.1977\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2016 - val_loss: 0.0706 - val_mae: 0.1994\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0728 - mae: 0.2008 - val_loss: 0.0699 - val_mae: 0.1927\n",
      "val: -0.005912512540817261\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0690 - mae: 0.1968 - val_loss: 0.0694 - val_mae: 0.1978\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0689 - mae: 0.1966 - val_loss: 0.0705 - val_mae: 0.1960\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0690 - mae: 0.1968 - val_loss: 0.0710 - val_mae: 0.1999\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0688 - mae: 0.1966 - val_loss: 0.0687 - val_mae: 0.1935\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1961 - val_loss: 0.0701 - val_mae: 0.2008\n",
      "val: 0.0029976069927215576\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0747 - mae: 0.2037 - val_loss: 0.0733 - val_mae: 0.1964\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0740 - mae: 0.2029 - val_loss: 0.0699 - val_mae: 0.1938\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0735 - mae: 0.2023 - val_loss: 0.0718 - val_mae: 0.2027\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0732 - mae: 0.2020 - val_loss: 0.0725 - val_mae: 0.1981\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0729 - mae: 0.2015 - val_loss: 0.0744 - val_mae: 0.1942\n",
      "val: -0.0021629631519317627\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0687 - mae: 0.1964 - val_loss: 0.0693 - val_mae: 0.1941\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0687 - mae: 0.1963 - val_loss: 0.0697 - val_mae: 0.1945\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0685 - mae: 0.1960 - val_loss: 0.0725 - val_mae: 0.2070\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1960 - val_loss: 0.0683 - val_mae: 0.1957\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0683 - mae: 0.1959 - val_loss: 0.0685 - val_mae: 0.1919\n",
      "val: -0.0021676719188690186\n",
      "-----batch 2-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.0723 - mae: 0.2006 - val_loss: 0.0715 - val_mae: 0.1947\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0722 - mae: 0.2005 - val_loss: 0.0702 - val_mae: 0.1967\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0720 - mae: 0.2002 - val_loss: 0.0745 - val_mae: 0.2072\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0718 - mae: 0.1997 - val_loss: 0.0710 - val_mae: 0.1979\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0716 - mae: 0.1995 - val_loss: 0.0692 - val_mae: 0.1935\n",
      "val: -0.0012017935514450073\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0683 - mae: 0.1960 - val_loss: 0.0745 - val_mae: 0.2064\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0680 - mae: 0.1957 - val_loss: 0.0683 - val_mae: 0.1957\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0679 - mae: 0.1958 - val_loss: 0.0692 - val_mae: 0.1987\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0679 - mae: 0.1957 - val_loss: 0.0680 - val_mae: 0.1927\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0677 - mae: 0.1954 - val_loss: 0.0673 - val_mae: 0.1894\n",
      "val: -0.017080843448638916\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0744 - mae: 0.2035 - val_loss: 0.0736 - val_mae: 0.2057\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2030 - val_loss: 0.0710 - val_mae: 0.1952\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0733 - mae: 0.2025 - val_loss: 0.0703 - val_mae: 0.1946\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0731 - mae: 0.2022 - val_loss: 0.0710 - val_mae: 0.1974\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0727 - mae: 0.2017 - val_loss: 0.0746 - val_mae: 0.1982\n",
      "val: -0.0074935853481292725\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0691 - mae: 0.1969 - val_loss: 0.0696 - val_mae: 0.1962\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0687 - mae: 0.1966 - val_loss: 0.0679 - val_mae: 0.1938\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0687 - mae: 0.1963 - val_loss: 0.0696 - val_mae: 0.1952\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0685 - mae: 0.1962 - val_loss: 0.0673 - val_mae: 0.1905\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0682 - mae: 0.1957 - val_loss: 0.0702 - val_mae: 0.2017\n",
      "val: 0.005481258034706116\n",
      "-----Epoch_5-----\n",
      "-----batch 1-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0727 - mae: 0.2007 - val_loss: 0.0702 - val_mae: 0.1968\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0723 - mae: 0.2001 - val_loss: 0.0697 - val_mae: 0.1940\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0720 - mae: 0.1999 - val_loss: 0.0703 - val_mae: 0.1948\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0723 - mae: 0.1999 - val_loss: 0.0721 - val_mae: 0.1964\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0719 - mae: 0.1995 - val_loss: 0.0694 - val_mae: 0.1958\n",
      "val: -0.0009621679782867432\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0687 - mae: 0.1965 - val_loss: 0.0664 - val_mae: 0.1930\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0685 - mae: 0.1963 - val_loss: 0.0747 - val_mae: 0.2031\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0687 - mae: 0.1965 - val_loss: 0.0776 - val_mae: 0.2090\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0683 - mae: 0.1960 - val_loss: 0.0697 - val_mae: 0.2009\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0682 - mae: 0.1960 - val_loss: 0.0663 - val_mae: 0.1908\n",
      "val: -0.0022312551736831665\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0743 - mae: 0.2035 - val_loss: 0.0729 - val_mae: 0.1992\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0739 - mae: 0.2029 - val_loss: 0.0732 - val_mae: 0.1986\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0736 - mae: 0.2024 - val_loss: 0.0713 - val_mae: 0.1924\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0734 - mae: 0.2023 - val_loss: 0.0736 - val_mae: 0.2035\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0729 - mae: 0.2016 - val_loss: 0.0702 - val_mae: 0.1971\n",
      "val: -0.002106890082359314\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0689 - mae: 0.1963 - val_loss: 0.0719 - val_mae: 0.2057\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0686 - mae: 0.1962 - val_loss: 0.0711 - val_mae: 0.2042\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0686 - mae: 0.1961 - val_loss: 0.0731 - val_mae: 0.1974\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0687 - mae: 0.1961 - val_loss: 0.0741 - val_mae: 0.2097\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 94s 30ms/step - loss: 0.0685 - mae: 0.1959 - val_loss: 0.0690 - val_mae: 0.1895\n",
      "val: -0.016193434596061707\n",
      "-----batch 2-----\n",
      "Traing model_1: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.0725 - mae: 0.2007 - val_loss: 0.0707 - val_mae: 0.1978\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0723 - mae: 0.2003 - val_loss: 0.0691 - val_mae: 0.1910\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0720 - mae: 0.2000 - val_loss: 0.0688 - val_mae: 0.1919\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0717 - mae: 0.1997 - val_loss: 0.0750 - val_mae: 0.1987\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0715 - mae: 0.1994 - val_loss: 0.0729 - val_mae: 0.2080\n",
      "val: 0.010282456874847412\n",
      "Traing model_2: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0676 - mae: 0.1952 - val_loss: 0.0745 - val_mae: 0.2093\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0677 - mae: 0.1954 - val_loss: 0.0720 - val_mae: 0.1950\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0677 - mae: 0.1952 - val_loss: 0.0759 - val_mae: 0.2018\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0674 - mae: 0.1951 - val_loss: 0.0661 - val_mae: 0.1889\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0675 - mae: 0.1950 - val_loss: 0.0693 - val_mae: 0.1913\n",
      "val: -0.01800839602947235\n",
      "Traing model_3: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.0744 - mae: 0.2037 - val_loss: 0.0723 - val_mae: 0.1989\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0741 - mae: 0.2029 - val_loss: 0.0726 - val_mae: 0.2055\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0735 - mae: 0.2027 - val_loss: 0.0721 - val_mae: 0.1997\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0734 - mae: 0.2024 - val_loss: 0.0696 - val_mae: 0.1948\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0726 - mae: 0.2015 - val_loss: 0.0736 - val_mae: 0.1945\n",
      "val: -0.004347845911979675\n",
      "Traing model_4: \n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 96s 30ms/step - loss: 0.0686 - mae: 0.1964 - val_loss: 0.0689 - val_mae: 0.1953\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0686 - mae: 0.1962 - val_loss: 0.0716 - val_mae: 0.2012\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0684 - mae: 0.1959 - val_loss: 0.0745 - val_mae: 0.2082\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0682 - mae: 0.1957 - val_loss: 0.0716 - val_mae: 0.2014\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.0680 - mae: 0.1954 - val_loss: 0.0676 - val_mae: 0.1920\n",
      "val: -0.003327891230583191\n"
     ]
    }
   ],
   "source": [
    "n_batch = x_train_ori.shape[0]//batch_size\n",
    "flag = True\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(f\"-----Epoch_{e+1}-----\")\n",
    "    x_mb = np.zeros((figures_size, batch_size, window_size))\n",
    "    for n, j in enumerate(range(n_batch)):\n",
    "        print(f\"-----batch {n+1}-----\")\n",
    "        x_mb_ori = x_train_ori[j*batch_size:(j+1)*batch_size]\n",
    "        t_mb,flag = get_t(x_mb_ori, y_train[j*batch_size:(j+1)*batch_size])\n",
    "        for i in range(figures_size):\n",
    "            x_mb[i] = x_train[i, j*batch_size:(j+1)*batch_size, :]\n",
    "        if flag:\n",
    "            true.append(t_mb)\n",
    "            p = forward_propagation(x_mb)\n",
    "            pred.append(p)\n",
    "            backpropagation(t_mb)\n",
    "            update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----batch 1-----\n",
      "Predicting by model 2!\n",
      "-----batch 2-----\n",
      "Predicting by model 2!\n",
      "-----batch 3-----\n",
      "Predicting by model 2!\n",
      "-----batch 4-----\n",
      "Predicting by model 2!\n",
      "-----batch 5-----\n",
      "Predicting by model 2!\n",
      "-----batch 6-----\n",
      "Predicting by model 2!\n",
      "-----batch 7-----\n",
      "Predicting by model 2!\n",
      "-----batch 8-----\n",
      "Predicting by model 2!\n",
      "-----batch 9-----\n",
      "Predicting by model 2!\n",
      "-----batch 10-----\n",
      "Predicting by model 2!\n",
      "-----batch 11-----\n",
      "Predicting by model 2!\n",
      "-----batch 12-----\n",
      "Predicting by model 2!\n",
      "-----batch 13-----\n",
      "Predicting by model 2!\n",
      "-----batch 14-----\n",
      "Predicting by model 2!\n",
      "-----batch 15-----\n",
      "Predicting by model 2!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_n(mat):\n",
    "    temp = []\n",
    "    for i in mat:\n",
    "        temp.append(np.argmax(i))\n",
    "\n",
    "    return max(temp,key=temp.count)\n",
    "\n",
    "test_batch_size = 10000\n",
    "x_test = []\n",
    "for i in range(figures_size):\n",
    "    x_test.append(x_test_ori[:, :, i])\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "n_batch = len(x_test_ori)//test_batch_size\n",
    "for j in range(n_batch):\n",
    "    print(f\"-----batch {j+1}-----\")\n",
    "\n",
    "    x_mb_test = np.zeros((figures_size, test_batch_size, window_size))\n",
    "\n",
    "    for i in range(figures_size):\n",
    "        x_mb_test[i] = x_test[i, j*test_batch_size:(j+1)*test_batch_size, :]\n",
    "\n",
    "    y_test_batch = y_test[j*test_batch_size:(j+1)*test_batch_size]\n",
    "\n",
    "    p = forward_propagation(x_mb_test)\n",
    "    pred.append(p)\n",
    "\n",
    "    n = get_n(p)\n",
    "    print(f\"Predicting by model {n+1}!\")\n",
    "\n",
    "    # pred_model = tf.keras.models.load_model(get_save_path(n),custom_objects={\"PositionalEmbedding\": PositionalEmbedding, \"Transformer_encoder\":Transformer_encoder})\n",
    "    # pred_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse',metrics=['mae'])\n",
    "    # x_test_batch = x_test_batch.reshape(x_test_batch.shape[0],10,15)\n",
    "    # pred_model.evaluate(x_test_batch, y_test_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
